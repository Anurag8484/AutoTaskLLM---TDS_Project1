AutoTaskLLM - LLM-Based Automation Agent
ğŸš€ AutoTaskLLM is an automation agent that executes multi-step tasks using a Large Language Model (GPT-4o-Mini). It parses natural language instructions and performs deterministic operations, making it a powerful tool for CI/CD pipelines and business automation.

ğŸ“Œ Features
âœ… Accepts plain-English tasks and executes them via an API
âœ… Uses GPT-4o-Mini to interpret task descriptions
âœ… Supports multi-step processing for various operations
âœ… Provides file content verification via a GET endpoint
âœ… Ensures security constraints: No data exfiltration or deletion
âœ… Containerized with Docker for easy deployment

âš™ï¸ Installation

1. Clone the Repository
bash
Copy
Edit
git clone <https://github.com/your-username/AutoTaskLLM.git>
cd AutoTaskLLM
2. Set Up Virtual Environment (Using UV)
bash
Copy
Edit
uv venv .  
source .venv/bin/activate  
3. Install Dependencies
bash
Copy
Edit
uv pip install -r requirements.txt
4. Set Up API Token (GPT-4o-Mini)
Create a .env file in the root directory:

ini
Copy
Edit
AIPROXY_TOKEN=your_openai_api_key
ğŸš€ Running the Application
Using Python (Development Mode)
bash
Copy
Edit
uvicorn src.api:app --host 0.0.0.0 --port 8000 --reload
Using Docker (Production Mode)
bash
Copy
Edit
docker build -t autotaskllm .
docker run -e AIPROXY_TOKEN=your_openai_api_key -p 8000:8000 autotaskllm
ğŸ› ï¸ API Endpoints
1ï¸âƒ£ Run a Task
http
Copy
Edit
POST /run?task=<task_description>
Executes a task based on natural language input
Uses LLM to interpret the instruction
Returns 200 OK on success, 400 Bad Request for invalid tasks
2ï¸âƒ£ Read a File
http
Copy
Edit
GET /read?path=<file_path>
Returns file contents for verification
Returns 404 Not Found if the file doesnâ€™t exist
ğŸ“‚ Project Structure
bash
Copy
Edit
AutoTaskLLM/
â”‚â”€â”€ data/                    # Stores generated & processed files
â”‚â”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ api.py               # FastAPI endpoints
â”‚   â”œâ”€â”€ task_handler.py       # Handles task execution
â”‚   â”œâ”€â”€ llm_agent.py          # Calls the LLM for parsing
â”‚   â”œâ”€â”€ utils.py              # Utility functions
â”‚â”€â”€ .env                      # API tokens (not committed)
â”‚â”€â”€ requirements.txt          # Dependencies
â”‚â”€â”€ Dockerfile                # Containerization
â”‚â”€â”€ README.md                 # Documentation
â”‚â”€â”€ LICENSE                   # MIT License
ğŸ“– Supported Tasks
Phase A: Operations Tasks
âœ… Formatting files using Prettier
âœ… Sorting JSON arrays
âœ… Extracting & processing logs
âœ… Counting specific occurrences in text files
âœ… Running SQL queries on SQLite

Phase B: Business Tasks
âœ… Fetching & storing API data
âœ… Git repository automation
âœ… SQL & DuckDB queries
âœ… Web scraping
âœ… Image compression & OCR
âœ… Audio transcription & Markdown conversion

ğŸ› ï¸ Contributing
Contributions are welcome! Please follow these steps:

Fork the repository
Create a new branch (feature/your-feature)
Commit changes (git commit -m "Added feature")
Push to your branch (git push origin feature/your-feature)
Create a Pull Request
